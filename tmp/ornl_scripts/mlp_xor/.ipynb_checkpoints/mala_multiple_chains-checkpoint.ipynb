{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MALA sampling of MLP weights using XOR data\n",
    "\n",
    "Learn the XOR function by sampling the weights of a multi-layer perceptron (MLP) via MALA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import packages\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.distributions import Normal\n",
    "\n",
    "from eeyore.data import XOR\n",
    "from eeyore.models import mlp\n",
    "from eeyore.kernels import NormalTransitionKernel\n",
    "from eeyore.mcmc import MALA\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load XOR data\n",
    "\n",
    "xor = XOR(dtype=torch.float64)\n",
    "dataloader = DataLoader(xor, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup MLP model\n",
    "\n",
    "hparams = mlp.Hyperparameters(dims=[2, 2, 1])\n",
    "model = mlp.MLP(hparams=hparams, dtype=torch.float64)\n",
    "model.prior = Normal(\n",
    "    torch.zeros(model.num_params(), dtype=model.dtype),\n",
    "    np.sqrt(3)*torch.ones(model.num_params(), dtype=model.dtype)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set number of chains, iterations, burnin iterations and MALA drift step\n",
    "\n",
    "num_chains = 10\n",
    "num_iterations = 110000\n",
    "num_burnin = 10000\n",
    "num_post_burnin = num_iterations - num_burnin\n",
    "\n",
    "drift_step = 1.74\n",
    "\n",
    "msg = \"Run {:\" + str(len(str(num_chains))) + \"}, duration {}, acceptance rate {}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run simulation and save output\n",
    "\n",
    "for i in range(num_chains):\n",
    "    # Setup MALA sampler\n",
    "    theta0 = model.prior.sample()\n",
    "    sampler = MALA(model, theta0, dataloader, step=drift_step)\n",
    "    \n",
    "    # Run MALA sampler\n",
    "    start_time = timer()\n",
    "    sampler.run(num_iterations=num_iterations, num_burnin=num_burnin)\n",
    "    end_time = timer()\n",
    "    print(msg.format(i+1, timedelta(seconds=end_time-start_time), sampler.chain.acceptance_rate()))\n",
    "\n",
    "    # Store all parameters in a single torch tensor\n",
    "    chain = torch.empty(num_post_burnin, model.num_params())\n",
    "    for j in range(model.num_params()):\n",
    "        chain[:, j] = torch.tensor(sampler.chain.get_theta(j))\n",
    "        \n",
    "    # Save tensor in file\n",
    "    with open(os.path.join(\"output\", \"mala\", \"gelman_rubin\", str(\"chain{:02d}.csv\".format(i+1))), 'w') as file:\n",
    "        np.savetxt(file, chain.cpu().detach().numpy(), delimiter=',', newline='\\n', header='')\n",
    "        \n",
    "    ## Save acceptance diagnostic for simulated Markov chain\n",
    "    with open(os.path.join(\"output\", \"mala\", \"gelman_rubin\", str(\"accepted{:02d}.txt\".format(i+1))), 'w') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for a in sampler.chain.vals['accepted']:\n",
    "            writer.writerow([a])\n",
    "            \n",
    "    ## Save runtime of simulation\n",
    "    with open(os.path.join(\"output\", \"mala\", \"gelman_rubin\", str(\"runtime{:02d}.txt\".format(i+1))), 'w') as file:\n",
    "        file.write(str(\"Runtime: {}\".format(timedelta(seconds=end_time-start_time))))\n",
    "        file.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
